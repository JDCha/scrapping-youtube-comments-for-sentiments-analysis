{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 44005,
     "status": "ok",
     "timestamp": 1545878285372,
     "user": {
      "displayName": "nitish tom Michael",
      "photoUrl": "https://lh5.googleusercontent.com/-JoPrizjDYDM/AAAAAAAAAAI/AAAAAAAAAFk/Z5m8usm5thM/s64/photo.jpg",
      "userId": "09075324258603060180"
     },
     "user_tz": -330
    },
    "id": "iUGYLwVcKHaG",
    "outputId": "69ba6119-4e58-4420-c172-a3df830e5559"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 20955,
     "status": "ok",
     "timestamp": 1545834416660,
     "user": {
      "displayName": "nitish tom Michael",
      "photoUrl": "https://lh5.googleusercontent.com/-JoPrizjDYDM/AAAAAAAAAAI/AAAAAAAAAFk/Z5m8usm5thM/s64/photo.jpg",
      "userId": "09075324258603060180"
     },
     "user_tz": -330
    },
    "id": "HSoYlMDrU053",
    "outputId": "3896f959-6186-49b7-c079-9a98338e77e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " commentsf.txt\t\t\t\t\t     'model.bin '\n",
      " comments.txt\t\t\t\t\t      negative.txt\n",
      "'complete nlp handling food comments dataset.ipynb'   positive.txt\n",
      " counts.txt\t\t\t\t\t      stopwords.txt\n",
      " labelf.txt\n"
     ]
    }
   ],
   "source": [
    "# !cat /content/gdrive/My\\ Drive/latest/comments.txt\n",
    "# !rm -r /content/gdrive/My\\ Drive/latest/senttencesf.txt\n",
    "\n",
    "#  !zcat /content/gdrive/My\\ Drive/latest/GoogleNews-vectors-negative300.bin.gz >/content/gdrive/My\\ Drive/latest/google.bin\n",
    "!ls /content/gdrive/My\\ Drive/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1484,
     "status": "ok",
     "timestamp": 1545882839809,
     "user": {
      "displayName": "nitish tom Michael",
      "photoUrl": "https://lh5.googleusercontent.com/-JoPrizjDYDM/AAAAAAAAAAI/AAAAAAAAAFk/Z5m8usm5thM/s64/photo.jpg",
      "userId": "09075324258603060180"
     },
     "user_tz": -330
    },
    "id": "5crbw87YzMVT",
    "outputId": "2b902f1c-6087-4f98-dd2b-46073704bcec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30080 of comments in the given dataset\n"
     ]
    }
   ],
   "source": [
    "# file = open('/content/gdrive/My Drive/latest/comments.txt',\"r\") #comments of  delhi video tours  especially food related\n",
    "# comments= file.read().splitlines()  \n",
    "# print(len(d),\"of comments in the given dataset\")\n",
    "# file.close()\n",
    "# with open('/content/gdrive/My Drive/latest/commentsf.txt', 'w') as f:\n",
    "#     for item in comments:\n",
    "#         f.write(\"%s\\n\" % list(item.split()))\n",
    "# file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12199,
     "status": "ok",
     "timestamp": 1545833059867,
     "user": {
      "displayName": "nitish tom Michael",
      "photoUrl": "https://lh5.googleusercontent.com/-JoPrizjDYDM/AAAAAAAAAAI/AAAAAAAAAFk/Z5m8usm5thM/s64/photo.jpg",
      "userId": "09075324258603060180"
     },
     "user_tz": -330
    },
    "id": "sZp-CpAcKIEb",
    "outputId": "d1c3cd25-626f-4deb-9fc3-67081960dae1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " commentsf.txt\t\t\t\t\t      negative.txt\n",
      " comments.txt\t\t\t\t\t      positive.txt\n",
      "'complete nlp handling food comments dataset.ipynb'   sentencesf.txt\n",
      " counts.txt\t\t\t\t\t      senttencesf.txt\n",
      " labelf.txt\t\t\t\t\t      stopwords.txt\n",
      "'model.bin '\n"
     ]
    }
   ],
   "source": [
    "!ls /content/gdrive/My\\ Drive/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 277559,
     "status": "ok",
     "timestamp": 1545887546520,
     "user": {
      "displayName": "nitish tom Michael",
      "photoUrl": "https://lh5.googleusercontent.com/-JoPrizjDYDM/AAAAAAAAAAI/AAAAAAAAAFk/Z5m8usm5thM/s64/photo.jpg",
      "userId": "09075324258603060180"
     },
     "user_tz": -330
    },
    "id": "nuLnKdlIV3C-",
    "outputId": "3c19da92-b4a2-4103-86eb-f6b111bec1db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30080 of comments in the given dataset\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file = open('/content/gdrive/My Drive/latest/comments.txt',\"r\") #comments of  delhi video tours  especially food related\n",
    "comments= file.read().splitlines()  \n",
    "print(len(comments),\"of comments in the given dataset\")\n",
    "file.close()\n",
    "\n",
    " \n",
    "\n",
    "filename = '/content/gdrive/My Drive/latest/negative.txt'\n",
    "file = open(filename,\"r\" )\n",
    "negative = file.read().splitlines()\n",
    "file.close()   \n",
    "\n",
    "filename = '/content/gdrive/My Drive/latest/positive.txt'\n",
    "file = open(filename,\"r\" )\n",
    "positive = file.read().splitlines()\n",
    "file.close()\n",
    "\n",
    "lab=[]\n",
    "for i in range(len(comments)):\n",
    "    lab.append(0)\n",
    "def label(comments,negative,positive):\n",
    "    for i in range(len(comments)):\n",
    "        words=comments[i].split()\n",
    "        for j in range(len(words)):\n",
    "            for k in range(len(positive)):\n",
    "                if(words[j]==positive[k]):\n",
    "                    lab[i]=1\n",
    "                \n",
    "            for l in range(len(negative)): \n",
    "                if(words[j]==negative[l]):\n",
    "                    lab[i]=2\n",
    "                \n",
    "           \n",
    "# label(comments,negative,positive)    \n",
    "# print(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1424,
     "status": "ok",
     "timestamp": 1545887735023,
     "user": {
      "displayName": "nitish tom Michael",
      "photoUrl": "https://lh5.googleusercontent.com/-JoPrizjDYDM/AAAAAAAAAAI/AAAAAAAAAFk/Z5m8usm5thM/s64/photo.jpg",
      "userId": "09075324258603060180"
     },
     "user_tz": -330
    },
    "id": "2xA4tH1MXYMb",
    "outputId": "295602e1-1019-424b-b6fa-c94928bacb83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338342\n",
      "30080\n"
     ]
    }
   ],
   "source": [
    "filename = '/content/gdrive/My Drive/latest/stopwords.txt'\n",
    "file = open(filename,\"r\" )\n",
    "stopwords = file.read().splitlines()\n",
    "file.close() \n",
    "d=comments\n",
    "words=[]\n",
    "sentences =[]\n",
    "k = []\n",
    "for i in range(len(d)):\n",
    "    sentences.append(0)\n",
    "for i in range(0,len(d)):\n",
    "    sentences[i]=d[i].split()\n",
    "    for j in sentences[i]:   \n",
    "        if(len(j)<9):         #part of filtering\n",
    "            words.append(j)\n",
    "wordsf= []\n",
    "words = [word.lower() for word in words]\n",
    "words = [word for word in words if word.isalpha()]# setting the vocabulary\n",
    "wordsf=(set(words).difference(stopwords))      \n",
    " \n",
    "print(len(words))\n",
    "words=list(wordsf)\n",
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1440,
     "status": "ok",
     "timestamp": 1545887740228,
     "user": {
      "displayName": "nitish tom Michael",
      "photoUrl": "https://lh5.googleusercontent.com/-JoPrizjDYDM/AAAAAAAAAAI/AAAAAAAAAFk/Z5m8usm5thM/s64/photo.jpg",
      "userId": "09075324258603060180"
     },
     "user_tz": -330
    },
    "id": "THO3wjOmObMk",
    "outputId": "ae438d14-8188-4ff0-feba-7a4d69608c69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27263 27263\n"
     ]
    }
   ],
   "source": [
    "j=[]\n",
    "sentencesf=[]         #calculating the length of all sentences ie the no. of words\n",
    "labelf=[]\n",
    "for i in range(len(sentences)):\n",
    "  j.append(len(sentences[i]))\n",
    "  \n",
    "for i in range(len(j)):\n",
    "  if(j[i]<=28):\n",
    "    sentencesf.append(sentences[i])\n",
    "    labelf.append(lab[i])\n",
    "with open('/content/gdrive/My Drive/latest/sentencesf.txt', 'w') as f:\n",
    "    for item in sentencesf:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "file.close()\n",
    "\n",
    "with open('/content/gdrive/My Drive/latest/labelf.txt', 'w') as f:\n",
    "    for item in labelf:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "file.close()\n",
    "print(len(sentencesf),len(labelf))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7157,
     "status": "ok",
     "timestamp": 1545898582049,
     "user": {
      "displayName": "nitish tom Michael",
      "photoUrl": "https://lh5.googleusercontent.com/-JoPrizjDYDM/AAAAAAAAAAI/AAAAAAAAAFk/Z5m8usm5thM/s64/photo.jpg",
      "userId": "09075324258603060180"
     },
     "user_tz": -330
    },
    "id": "BAx_v8WdqJyr",
    "outputId": "6253b3bb-b88e-4fcd-b545-56ae07b7a470"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "\n",
    "# define training data\n",
    "# print((comments[5]))\n",
    "# train model\n",
    "# filename='/content/gdrive/My Drive/latest/sentencesf.txt'\n",
    "# file = open(filename,\"r\" )\n",
    "# sentencesf= file.read().splitlines()\n",
    "# file.close()\n",
    "model = Word2Vec(sentencesf,size=28, min_count=1)#word vector dim=28\n",
    "# summarize the loaded model\n",
    "print(model)\n",
    "# summarize vocabulary\n",
    "words = list(model.wv.vocab)\n",
    "print(words)\n",
    "# access vector for one word\n",
    "print(model[ 'was' ])\n",
    "# save model\n",
    "\n",
    "zerovector=[]\n",
    "for i in range(28):\n",
    "  zerovector.append(0)\n",
    "\n",
    "filename='/content/gdrive/My Drive/latest/labelf.txt'\n",
    "file = open(filename,\"r\" )\n",
    "labelf= file.read().splitlines()\n",
    "file.close()\n",
    "\n",
    "\n",
    "\n",
    "# print(label)\n",
    "\n",
    "def sentencevector(sent):\n",
    "  vector=[]\n",
    "  for word in sent:\n",
    "       vector.append(model[word])\n",
    "  if(len(sent)<28):\n",
    "    for i in range(len(sent),28):\n",
    "      vector.append(zerovector)\n",
    "  return(vector)\n",
    "\n",
    "Xtotal=[]\n",
    "Ytotal=labelf\n",
    "for i in range(len(sentencesf)):\n",
    "  a=np.array(sentencevector(sentencesf[i]))\n",
    "  Xtotal.append(a)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 27054,
     "status": "ok",
     "timestamp": 1545898780271,
     "user": {
      "displayName": "nitish tom Michael",
      "photoUrl": "https://lh5.googleusercontent.com/-JoPrizjDYDM/AAAAAAAAAAI/AAAAAAAAAFk/Z5m8usm5thM/s64/photo.jpg",
      "userId": "09075324258603060180"
     },
     "user_tz": -330
    },
    "id": "De1RcxjW8ByR",
    "outputId": "a9d2320e-7240-404a-e80b-614ce75df76d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 4s 215us/step - loss: 0.8506 - acc: 0.6190\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 2s 112us/step - loss: 0.8012 - acc: 0.6348\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 2s 110us/step - loss: 0.7825 - acc: 0.6470\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 2s 109us/step - loss: 0.7685 - acc: 0.6556\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 2s 108us/step - loss: 0.7542 - acc: 0.6629\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 2s 104us/step - loss: 0.7444 - acc: 0.6713\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 2s 111us/step - loss: 0.7290 - acc: 0.6769\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 2s 114us/step - loss: 0.7185 - acc: 0.6857\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 2s 109us/step - loss: 0.7039 - acc: 0.6943\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 2s 102us/step - loss: 0.6900 - acc: 0.6986\n",
      "7263/7263 [==============================] - 1s 158us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7658563222780743, 0.6732755058825747]"
      ]
     },
     "execution_count": 108,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "Xtrain=np.array(Xtotal[:20000])\n",
    "Xtest=np.array(Xtotal[20000:27263])\n",
    "Y_train=np.array(Ytotal[:20000])\n",
    "Y_test=np.array(Ytotal[20000:27263])\n",
    "X_train = Xtrain.reshape(Xtrain.shape[0], 28, 28 , 1).astype('float32')\n",
    "X_test=Xtest.reshape(Xtest.shape[0], 28, 28 , 1).astype('float32')\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(100, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dropout(0.5),\n",
    "  tf.keras.layers.Dense(50, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(3, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=10)\n",
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 263
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1222470,
     "status": "ok",
     "timestamp": 1545900189347,
     "user": {
      "displayName": "nitish tom Michael",
      "photoUrl": "https://lh5.googleusercontent.com/-JoPrizjDYDM/AAAAAAAAAAI/AAAAAAAAAFk/Z5m8usm5thM/s64/photo.jpg",
      "userId": "09075324258603060180"
     },
     "user_tz": -330
    },
    "id": "463sMaEuHtDB",
    "outputId": "a16e7848-918e-462c-ddb9-acfba5efd051"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 12263 samples\n",
      "Epoch 1/5\n",
      "15000/15000 [==============================] - 239s 16ms/step - loss: 6.3904e-08 - acc: 0.2759 - val_loss: 6.7620e-08 - val_acc: 0.2937\n",
      "Epoch 2/5\n",
      "15000/15000 [==============================] - 234s 16ms/step - loss: 6.3904e-08 - acc: 0.2759 - val_loss: 6.7620e-08 - val_acc: 0.2937\n",
      "Epoch 3/5\n",
      "15000/15000 [==============================] - 235s 16ms/step - loss: 6.3904e-08 - acc: 0.2759 - val_loss: 6.7620e-08 - val_acc: 0.2937\n",
      "Epoch 4/5\n",
      "15000/15000 [==============================] - 237s 16ms/step - loss: 6.3904e-08 - acc: 0.2759 - val_loss: 6.7620e-08 - val_acc: 0.2937\n",
      "Epoch 5/5\n",
      "15000/15000 [==============================] - 236s 16ms/step - loss: 6.3904e-08 - acc: 0.2759 - val_loss: 6.7620e-08 - val_acc: 0.2937\n",
      "Test loss: 6.761965409077994e-08\n",
      "Test accuracy: 0.29372910380820355\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "Xtrain=np.array(Xtotal[:15000])\n",
    "Xtest=np.array(Xtotal[15000:27263])\n",
    "Y_train=np.array(Ytotal[:15000])\n",
    "Y_test=np.array(Ytotal[15000:27263])\n",
    "X_train = Xtrain.reshape(Xtrain.shape[0], 28, 28 , 1).astype('float32')\n",
    "X_test=Xtest.reshape(Xtest.shape[0], 28, 28 , 1).astype('float32')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(200, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(28,28,1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train,\n",
    "          batch_size=40,\n",
    "          epochs=5,\n",
    "          \n",
    "          validation_data=(X_test, Y_test))\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YAa3flsgmHdA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "tokenizer.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
