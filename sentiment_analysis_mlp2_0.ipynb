{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment analysis mlp2.0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "vZa055NgwEv-",
        "colab_type": "code",
        "outputId": "be075be8-73e6-4104-ead2-21c3ef7c170f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "from gensim.models import Word2Vec\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "5ielHM1z1h1K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*Labeling  the statements as  neutral(0), positive(1) and negative(2) *\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "oU7DNWwg0Nb4",
        "colab_type": "code",
        "outputId": "135c6a5b-b41f-4a27-983f-439d8ee5aa5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive')\n",
        "\n",
        "file = open('/content/gdrive/My Drive/latest/comments.txt',\"r\") #comments of  delhi video tours  especially food related\n",
        "comments= file.read().splitlines()  \n",
        "print(len(comments),\"of comments in the given dataset\")\n",
        "file.close()\n",
        "\n",
        "# filename = '/content/gdrive/My Drive/latest/negative.txt'\n",
        "# file = open(filename,\"r\" )\n",
        "# negative = file.read().splitlines()\n",
        "# file.close()   \n",
        "\n",
        "# filename = '/content/gdrive/My Drive/latest/positive.txt'\n",
        "# file = open(filename,\"r\" )\n",
        "# positive = file.read().splitlines()\n",
        "# file.close()\n",
        "\n",
        "# lab=[]\n",
        "# for i in range(len(comments)):\n",
        "#     lab.append(0)\n",
        "# def label(comments,negative,positive):\n",
        "#     for i in range(len(comments)):\n",
        "#         words=comments[i].split()\n",
        "#         for j in range(len(words)):\n",
        "#             for k in range(len(positive)):\n",
        "#                 if(words[j]==positive[k]):\n",
        "#                     lab[i]=.7\n",
        "                \n",
        "#             for l in range(len(negative)): \n",
        "#                 if(words[j]==negative[l]):\n",
        "#                     lab[i]=.5\n",
        "                \n",
        "           \n",
        "# label(comments,negative,positive)\n",
        "# np.save('/content/gdrive/My Drive/latest/labelf.npy', lab)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "30080 of comments in the given dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EjU6WKPbAzsG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*Vocabulary building section *\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "gdlgsvCFzn5-",
        "colab_type": "code",
        "outputId": "dbe4e053-8ce4-46c6-b937-f87b4673bff4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(comments[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "you should try coming to Tunisia \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HY5zbNFA0TVR",
        "colab_type": "code",
        "outputId": "60fd80e1-1837-4401-e25d-30a11d887dd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import string\n",
        "with open('/content/gdrive/My Drive/latest/commentss.txt', 'w') as f:\n",
        "    for item in comments:\n",
        "      words=\" \".join(\"\".join([\" \" if ch in string.punctuation else ch for ch in item]).split())\n",
        "      wordsf=\"\".join(str(x) for x in list(words))\n",
        "      f.write(\"%s\\n\" % wordsf)\n",
        "file.close()\n",
        "file = open('/content/gdrive/My Drive/latest/commentss.txt',\"r\") #comments of  delhi video tours  especially food related\n",
        "commentss= file.read().splitlines()  \n",
        "print(len(comments),\"of comments in the given dataset\")\n",
        "file.close()\n",
        "a=[]\n",
        "for c in string.punctuation:\n",
        "    a.append(c)\n",
        "with open('/content/gdrive/My Drive/latest/commentssss.txt', 'w') as f:\n",
        "    for item in commentss:\n",
        "      words=(set(item.split()).difference(a))\n",
        "      wordsf=\" \".join(str(x.lower()) for x in list(words))\n",
        "      f.write(\"%s\\n\" % wordsf)\n",
        "file.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30080 of comments in the given dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VLrJ9ktOBZcv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*Removing larger sentences and retaining only ones with the length specified or lesser ones*\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "wV7ICuT63MFb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "j=[]\n",
        "sentencesf=[]         #calculating the length of all sentences ie the no. of words\n",
        "labelf=[]\n",
        "filename = '/content/gdrive/My Drive/latest/commentssss.txt'\n",
        "file = open(filename,\"r\" )\n",
        "sentences = file.read().splitlines()\n",
        "file.close() \n",
        "lab=np.load('/content/gdrive/My Drive/latest/labelf.npy')\n",
        "for i in range(len(sentences)):\n",
        "  j.append(len(sentences[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AGqljyiZS81I",
        "colab_type": "code",
        "outputId": "aee0ebf9-3efb-48c3-cb6c-986b68898220",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "sense=[]\n",
        "for i in range(len(sentences)):\n",
        "    sense.append(0)\n",
        "for i in range(0,len(sentences)):\n",
        "    sense[i]=sentences[i].split()\n",
        "    \n",
        "sentencesf=[]\n",
        "labelf=[]\n",
        "j=[]\n",
        "for i in range(len(sentences)):\n",
        "  j.append(len(sense[i]))\n",
        "\n",
        "\n",
        "for i in range(len(j)):\n",
        "  if(j[i]<=68):\n",
        "    sentencesf.append(sense[i])\n",
        "    labelf.append(lab[i])\n",
        "print(type(sentencesf))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iOYi4SvmBxfK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "*Word2Vec*\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "L1hk-dJT3s8b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Word2Vec(sentencesf,size=68, min_count=5)#word vector dim=28\n",
        "# summarize the loaded model\n",
        "print(model)\n",
        "# summarize vocabulary\n",
        "words = list(model.wv.vocab)\n",
        "print(words)\n",
        "# access vector for one word\n",
        "# print(model[ 'was' ])\n",
        "# save model\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R1qa9zqLBNkj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*Padding for MLP*\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "QTIIDjt75rjx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "zerovector=[]\n",
        "for i in range(68):\n",
        "  zerovector.append(0)\n",
        "# print(label)\n",
        "def sentencevector(sent):\n",
        "  vector=[]\n",
        "  for word in sent:\n",
        "    if(word  in words):\n",
        "       vector.append(model[word])\n",
        "    else:\n",
        "      vector.append(zerovector)\n",
        "  if(len(sent)<68):\n",
        "    for i in range(len(sent),68):\n",
        "      vector.append(zerovector)\n",
        "  return(vector)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1Cp3Bt1sB41_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*Splitting into training and test data*\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "yKsFfxxq5vx5",
        "colab_type": "code",
        "outputId": "8400070b-f6e1-48bd-f56f-f6ada70fb2ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "Xtotal=[]\n",
        "Ytotal=labelf\n",
        "for i in range(len(sentencesf)):\n",
        "  a=np.array(sentencevector(sentencesf[i]))\n",
        "  Xtotal.append(a)\n",
        "\n",
        "Xtrain=np.array(Xtotal[:20000])\n",
        "Xtest=np.array(Xtotal[20000:27263])\n",
        "Y_train=np.array(Ytotal[:20000])\n",
        "Y_test=np.array(Ytotal[20000:27263])\n",
        "X_train = Xtrain.reshape(Xtrain.shape[0], 68, 68 , 1).astype('float32')\n",
        "X_test=Xtest.reshape(Xtest.shape[0], 68, 68 , 1).astype('float32')\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "o8PydhgPCDTl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*Model construction*\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "pcJB6ndG5zk_",
        "colab_type": "code",
        "outputId": "38218c3d-55d7-41bb-8439-717bbf6465fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(700, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dropout(0.3),\n",
        "  tf.keras.layers.Dense(100, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(3, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, Y_train, epochs=1)\n",
        "model.evaluate(X_test, Y_test)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "20000/20000 [==============================] - 32s 2ms/step - loss: 0.0070 - acc: 0.5485\n",
            "7263/7263 [==============================] - 2s 266us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.4859545366392943e-05, 0.5361420899920928]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "10YFt3gbizSs",
        "colab_type": "code",
        "outputId": "7e9d2550-ca4f-4378-bbdd-c05595560e47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  323750    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              multiple                  7100      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              multiple                  303       \n",
            "=================================================================\n",
            "Total params: 331,153\n",
            "Trainable params: 331,153\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Pz8y-ORHiQTs",
        "colab_type": "code",
        "outputId": "59c1b4b3-1960-4002-df22-751b0d0d7245",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "SVG(model_to_dot(model).create(prog='dot', format='svg'))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"45pt\" viewBox=\"0.00 0.00 802.00 45.00\" width=\"802pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 41)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-41 798,-41 798,4 -4,4\" stroke=\"transparent\"/>\n<!-- 139941969835960 -->\n<g class=\"node\" id=\"node1\">\n<title>139941969835960</title>\n<polygon fill=\"none\" points=\"0,-.5 0,-36.5 113,-36.5 113,-.5 0,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"56.5\" y=\"-14.8\">flatten_1: Flatten</text>\n</g>\n<!-- 139941969838032 -->\n<g class=\"node\" id=\"node2\">\n<title>139941969838032</title>\n<polygon fill=\"none\" points=\"131,-.5 131,-36.5 238,-36.5 238,-.5 131,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"184.5\" y=\"-14.8\">dense_3: Dense</text>\n</g>\n<!-- 139941969837528 -->\n<g class=\"node\" id=\"node3\">\n<title>139941969837528</title>\n<polygon fill=\"none\" points=\"256.5,-.5 256.5,-36.5 390.5,-36.5 390.5,-.5 256.5,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"323.5\" y=\"-14.8\">dropout_2: Dropout</text>\n</g>\n<!-- 139941969837472 -->\n<g class=\"node\" id=\"node4\">\n<title>139941969837472</title>\n<polygon fill=\"none\" points=\"409,-.5 409,-36.5 516,-36.5 516,-.5 409,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"462.5\" y=\"-14.8\">dense_4: Dense</text>\n</g>\n<!-- 139941969837024 -->\n<g class=\"node\" id=\"node5\">\n<title>139941969837024</title>\n<polygon fill=\"none\" points=\"534.5,-.5 534.5,-36.5 668.5,-36.5 668.5,-.5 534.5,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"601.5\" y=\"-14.8\">dropout_3: Dropout</text>\n</g>\n<!-- 139941969836968 -->\n<g class=\"node\" id=\"node6\">\n<title>139941969836968</title>\n<polygon fill=\"none\" points=\"687,-.5 687,-36.5 794,-36.5 794,-.5 687,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"740.5\" y=\"-14.8\">dense_5: Dense</text>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    }
  ]
}